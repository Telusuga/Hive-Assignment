1)What is the definition of Hive? What is the present version of Hive? 
Answer:Hive is a computation engine in which it runs on top of MAP REDUCE Program.In order to write a Map Reduce code is written in JAVA in order to reduce the overhead of writing multiple lines of code.
Instead of writing code in MAP REDUCE we can use Hive Query Language(HQL) in order to get the results.
Version--->Hive 1.1.0-cdh5.13.0
Present hive version-->3.1.3

2)Is Hive suitable to be used for OLTP systems? Why?
Answer:Hive basically supports OLAP because it has the capability to do the analysis on top of huge amount of data.
Hive is very much suitable for batch processing and it doesnot support inserts and updates at row level.
But in the later versions of hive it also supports the updates after 0.14.

3)How is HIVE different from RDBMS? Does hive support ACID transactions. If not then give the proper reason
Answer:In general RDBMS we perform general SQL operations on a database but in Hive the operations are performed on Data warehouse.
One of the main difference is Hive is "Schema On Read" where as general RDBMS is "Schema On Write". Hive does support ACID properties.
For a table to perform ACID properties it must follow 4 steps:
(a) It must be a Internal/Managed Table.
(b) It should be bucketed/clustered.
(c) The table format must be in ORC.
(d) The transactional Property should be set to true.
Note: The ACID properties came into hive starting from Version 0.14.

4)Explain the hive architecture and the different components of a Hive architecture?
Answer:The main components of Hive are 
a)Driver: This is the main part in Hive in which it contains 4 main blocks:
                                                      1)Parser:This is used to check the syntax and schemantics.
                                                      2)Planner:This is used to put out the various execution plans.
                                                      3)Optimizer:This is used to select the best execution plan in which is low in terms of cost and faster in execution.
                                                      4)Executioner:This is used to execute the output plan of the optimizer. The execution is mainly done by Map-Reduce code

b)Metastore: DerbyDB is used as a Metastore in which it is used to store the metainfo.

c)Thrift: This is a daemon service in Hive which allows the connectivity of other services to connect to Hive through ODBC/JDBC connections.

d)CLI: Through HUE we can connect to Hive and perform analytics using HUE.

5. Mention what Hive query processor does? And Mention what are the components of a Hive query processor?
Answer: The Hive Query Processor will convert the give HQL statement into Map Reduce job.
Components of Hive Query Processor are:
a)Parse and SemanticAnalysis: Here the syntax check will be taken place.
b)Optimizer:It checks which plan will be cost efficenient to execute.
c)Plan Components: The components for the generated plan will be created.
d)Map/Reduce Execution Engine: Here the execution of hive job will take place.
e)Sessions: The connection will be created for the particular Hive Job.
f)Hive Function Framework: In this component the necessary hive functions will be generated as per the plan.
g)Type interfaces
h)Tools


6. What are the three different modes in which we can operate Hive?
Answer:There are 2 modes in Hive
a)Local Mode: In this there is only a single data node
b)Map-Reduce Mode: In this there are multiple data nodes.

7. Features and Limitations of Hive.
Answer:
Features:
a) Hive is schema on read.
b) Hive is built on top of Map-Reduce.
c) Hive uses HQL which is similar to SQL.

Limitation:
a)Hive does not support Real Time processing.
b)High Latency.

8. How to create a Database in HIVE?
Answer:
create database database_name;

9. How to create a table in HIVE?
Answer:
create table table_name(
column_names column_type
)
row format delimited
fields terminated by 'column_delimiter';

10.What do you mean by describe and describe extended and describe formatted with respect to database and table
Answer:
describe table-->shows the list of columns.
describe database-->shows the name od database along with root location on hdfs.

describe table extented-->It shows the metadata of the table.
describe table formatted-->It shows the metadata in tabular format.

11.How to skip header rows from a table in Hive?
Answer: while creating the table we need to add the table property at last.
Ex:tblproperty("skip.header.line.count"="1")

12.What is a hive operator? What are the different types of hive operators?
Answer:Hive Operator is used to perform mathematical operation on hive.
Types of Hive Operators:
a)Relational Operators
b)Arithmetic Operators
c)Logical Operators
d)Complex Operators

13.Explain about the Hive Built-In Functions
Answer:The following are the hive built in functions which are mentioned below:
a)upper(string)-->Returns the string in upper letters
b)lower(string)-->Returns the string in lower letters
c)trim(string)-->Returns the string after removing the spaces
d)ltrim(string)-->Returns the string after removing the spaces on left
d)rtrim(string)-->Returns the string after removing the spaces on right
e)unixtime(column, the_column_format)-->Returns the unix time for the value of the column in the mentioned column format. Mostly used to convert the non-date format to date format.
f)from_unixtime(unixtime, date_format)-->Returns the date in the mentioned date format from the unix timestamp.
g)year(date)-->generates only the year from the date as output from complete date.
h)month(date)-->generates only the month from the date as output from complete date.
i)day(date)-->generates only the day from the date as output from complete date.
j)concat(string 1, string 2)-->combines the both string and generates output based on string 1+string 2

14. Write hive DDL and DML commands.
Answer:DDL-->CREATE,ALTER,DROP
       DML-->LOAD DATA,INSERT,IMPORT,EXPORT,DELETE,SELECT

15.Explain about SORT BY, ORDER BY, DISTRIBUTE BY and CLUSTER BY in Hive.       
Answer: SORT BY-->If there are many reducers then each reducer will do the sorting individually.
        ORDER BY-->The sorting will be happened overall on complete reducers.
        DISTRIBUTE BY-->This will ensure the column values in which we mentioned the column will go to the same reducer.
        Cluster BY-->The Clustering is a combination on DISTRIBUTE BY + SORT BY in which a particular column will be gone to a particular reducer and sorting will happen on the individual reducer.
       
16.Difference between "Internal Table" and "External Table" and Mention when to choose “Internal Table” and “External Table” in Hive?
Answer: The only difference between the Internal and external table is the place from which the data gets inserted into the hive table.
For an internal table if the table gets removed then the data stored in hdfs will also be removed.
But, for an external table if the table gets removed or dropped the data will not be removed as while craeting the table we will mention the data location.
Reason to choose an external table is when any data is residing on the external source such as other databases. If any issue happens on the table the data will not get effected
If the want to truncate external table it is not possible as data is not managed by Hive.
For Internal table management of tables is done by Hive.

17.Where does the data of a Hive table get stored?
Answer:Default it will be stored in /user/hive/warehouse/table_name/ directory in HDFS for Internal Table. For external table we can store in anywhere in HDFS.

18.Is it possible to change the default location of a managed table?
Answer: Yes we can change it by mentioning LOCATION <hdfs path> at last while creating table.
                                                     
19.What is a metastore in Hive? What is the default database provided by Apache Hive for metastore?                                                     
Answer: Metastore will be storing all the metadata info regarding the tables in Hive.
        The Default metastore for Apache Hive is DerbyDB.
 
 
20.Why does Hive not store metadata information in HDFS?
Answer:Because Hive already contains the Metadata DB which is Derby DB in which it is used to store all the metadata info.

21.What is a partition in Hive? And Why do we perform partitioning in Hive?
Answer:Partition means to divide the data based on a particular column or group of columns. Partition is one of the parameters inorder to increase the query performance in Hive.

22.What is the difference between dynamic partitioning and static partitioning?
Answer: In Static partition we need to mention on which column value the data should be partitioned.
But, in Dynamic partition only we should mention on column.

23.How do you check if a particular partition exists?
Answer: SHOW PARTITIONS table_name--> This will list out all the partitions for the table.
        SHOW PARTITIONS table_name [PARTITION(column)]--> This will check whether a particular column is partitioned are not.
        
24.How can you stop a partition form being queried?
Answer:ALTER TABLE table_name ENABLE OFFLINE

25.Why do we need buckets? How Hive distributes the rows into buckets?
Answer:Bucketing is similar to partitioning whereas in partitioning we will separate data based on repeated values but in bucketing we will separate data which is not repeating.
Hive distributes the data into buckets based on some hash function for will the resultant output generated will be going to the bucket.

26.In Hive, how can you enable buckets?
Answer: set hive.enforce.bucketing=true

27.How does bucketing help in the faster execution of queries?
Answer:Bucketing is used to increase the query performance in which bucketing will store the data based on the hash value. So, if we try to fetch a value it will try to fetch for the hash value output for which it will not try to waste the execution time.

28.How to optimise Hive Performance? Explain in very detail.
Answer:We can optimize by using Partitioning and Bucketing.
Partitioning-->It will try to separate the data based on the column which is repeated.
Bucketing-->We should use bucketing on the column for which there is no repeatition of values.

29. What is the use of Hcatalog?
Answer:Hcatalog is used to send the metadata of the tables in hive to other Hadoop application such as Pig, MapReduce.

30. Explain about the different types of join in Hive.
Answer:There are 4 types of Join in Hive
a)Left Join:Only the records on the left table and the records which are matching with right table will be present.
b)Right Join:Only the records on the right table and the records which are matching with left table will be present.
c)Inner Join:Only the matching records in both left and right tables will be present.
d)Full Outer Join:It is the combination of left join and right join.

The type of joins in Map Reduce are 
a)Reduce Side Join:When the data in the Map side is very small compared to the data in Reducer.
b)Map Side Join: When the data in the Map Side is huge compared to the Reducer then the reducer complete data will be shared to each mapper task.
c)Bucket Map Join: When the date is huge on both sides of Mapper and Reducer. Then, the buckets which contain the data will be moved to the reducer which contains the 
                   range of hash value.
d)Sorted Merge Bucket Map Join: It is an extension to Bucket Map Join in which the sorting is applied on both sides.

31.Is it possible to create a Cartesian join between 2 tables, using Hive?
Answer:Yes, it is possible to perform cartesian join or cross join in hive.

32.Explain the SMB Join in Hive?
Answer:Sorted Merge Bucket Join is an extension to Bucket Map Join in which the join there will be the use of Bucketing in which the data is separated based on the hash value generated.
So, when the join is about to happen on the required Mapper and Reducer will be involved in the join based on the hash value range. If we sort the values in both the Mapper and Reducer then it will be SMB Join.

33.What is the difference between order by and sort by which one we should use?
Answer:In Order By the output will be a single output but while using sort by there will be outputs based on number of reducers.

34.What is the usefulness of the DISTRIBUTED BY clause in Hive?
Answer:Distributed By is used to when we mention the columns they will go to same reducer.

38.Can a table be renamed in Hive?
Answer:ALTER TABLE table_name RENAME TO new_table_name

35.How does data transfer happen from HDFS to Hive?
Answer:hadoop fs -put file_name <hadoop_path>

37.What will happen in case you have not issued the command: ‘SET hive.enforce.bucketing=true;’ before bucketing a table in Hive?
Answer:If it is not set then uneven number of files will be generated irrespective of number of reducers.
If we set the property then number of reducers will be correct as per mentioned in cluster by during table creattion.
